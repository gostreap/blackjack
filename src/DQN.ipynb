{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from base_learning import BaseLearning\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "from env_v1 import BlackjackEnv\n",
    "from env_v3 import BlackjackDoubleDownSplitEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creation du modèle de DL\n",
    "\n",
    "class DQNSolver(nn.Module):\n",
    "    \"\"\"\n",
    "    Convolutional Neural Net with 3 conv layers and two linear layers\n",
    "    \"\"\"\n",
    "    def __init__(self, input_shape, n_actions):\n",
    "        super(DQNSolver, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(input_shape, 30),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(30, n_actions)\n",
    "        )\n",
    "    \n",
    "\n",
    "    def forward(self, x):\n",
    "        #x = self.fc(x)#.view(x.size()[0], -1)\n",
    "        return self.fc(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNAgent:\n",
    "\n",
    "    def __init__(self, env, max_memory_size, batch_size, gamma, lr, epsilon):\n",
    "\n",
    "        # Define DQN Layers\n",
    "        self.env = env\n",
    "        self.state_space = len(env.observation_space)\n",
    "        self.action_space = env.action_space.n\n",
    "        #self.pretrained = pretrained\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        \n",
    "        # DQN network  \n",
    "        self.dqn = DQNSolver(self.state_space, self.action_space).to(self.device)\n",
    "        \n",
    "        self.optimizer = torch.optim.Adam(self.dqn.parameters(), lr=lr)\n",
    "\n",
    "        # Create memory\n",
    "        self.max_memory_size = max_memory_size\n",
    "        self.STATE_MEM = torch.zeros(max_memory_size, self.state_space)\n",
    "        self.ACTION_MEM = torch.zeros(max_memory_size, 1)\n",
    "        self.REWARD_MEM = torch.zeros(max_memory_size, 1)\n",
    "        self.STATE2_MEM = torch.zeros(max_memory_size, self.state_space)\n",
    "        self.DONE_MEM = torch.zeros(max_memory_size, 1)\n",
    "        self.ending_position = 0\n",
    "        self.num_in_queue = 0\n",
    "        \n",
    "        self.memory_sample_size = batch_size\n",
    "        \n",
    "        # Learning parameters\n",
    "        self.gamma = gamma\n",
    "        self.l1 = nn.SmoothL1Loss().to(self.device) \n",
    "        self.epsilon = epsilon\n",
    "\n",
    "    def remember(self, state, action, reward, state2, done):\n",
    "        \"\"\"Store the experiences in a buffer to use later\"\"\"\n",
    "        self.STATE_MEM[self.ending_position] = state.float()\n",
    "        self.ACTION_MEM[self.ending_position] = action.float()\n",
    "        self.REWARD_MEM[self.ending_position] = reward.float()\n",
    "        self.STATE2_MEM[self.ending_position] = state2.float()\n",
    "        self.DONE_MEM[self.ending_position] = done.float()\n",
    "        self.ending_position = (self.ending_position + 1) % self.max_memory_size  # FIFO tensor\n",
    "        self.num_in_queue = min(self.num_in_queue + 1, self.max_memory_size)\n",
    "    \n",
    "    def batch_experiences(self):\n",
    "        \"\"\"Randomly sample 'batch size' experiences\"\"\"\n",
    "        idx = random.choices(range(self.num_in_queue), k=self.memory_sample_size)\n",
    "        STATE = self.STATE_MEM[idx]\n",
    "        ACTION = self.ACTION_MEM[idx]\n",
    "        REWARD = self.REWARD_MEM[idx]\n",
    "        STATE2 = self.STATE2_MEM[idx]\n",
    "        DONE = self.DONE_MEM[idx]      \n",
    "        return STATE, ACTION, REWARD, STATE2, DONE\n",
    "    \n",
    "    def act(self, state, train):\n",
    "        \"\"\"Epsilon-greedy action\"\"\"\n",
    "        if (random.random() < self.epsilon) and train:  \n",
    "            return torch.tensor([[env.action_space.sample()]])\n",
    "        else:\n",
    "            return torch.argmax(self.dqn(state.to(self.device))).unsqueeze(0).unsqueeze(0).cpu()\n",
    "    \n",
    "    def experience_replay(self):\n",
    "        if self.memory_sample_size > self.num_in_queue:\n",
    "            return\n",
    "    \n",
    "        # Sample a batch of experiences\n",
    "        STATE, ACTION, REWARD, STATE2, DONE = self.batch_experiences()\n",
    "        STATE = STATE.to(self.device)\n",
    "        ACTION = ACTION.to(self.device)\n",
    "        REWARD = REWARD.to(self.device)\n",
    "        STATE2 = STATE2.to(self.device)\n",
    "        DONE = DONE.to(self.device)\n",
    "        \n",
    "        self.optimizer.zero_grad()\n",
    "        # Q-Learning target is Q*(S, A) <- r + γ max_a Q(S', a) \n",
    "        target = REWARD + torch.mul((self.gamma * self.dqn(STATE2).max(1).values.unsqueeze(1)), 1 - DONE)\n",
    "        current = self.dqn(STATE).gather(1, ACTION.long())\n",
    "        \n",
    "        loss = self.l1(current, target)\n",
    "        loss.backward() # Compute gradients\n",
    "        self.optimizer.step() # Backpropagate error\n",
    "\n",
    "        #self.exploration_rate *= self.exploration_decay\n",
    "    def run(self,num_episodes,train):\n",
    "        total_rewards = []\n",
    "        win = 0\n",
    "        draw = 0\n",
    "        loss = 0\n",
    "        for ep_num in range(num_episodes):\n",
    "            state = list(self.env.reset())\n",
    "            state = torch.Tensor([state])\n",
    "            total_reward = 0\n",
    "            steps = 0\n",
    "            while True:\n",
    "                action = self.act(state,train)\n",
    "                steps += 1\n",
    "                \n",
    "                state_next, reward, terminal, info = self.env.step(int(action[0]))\n",
    "                total_reward += reward\n",
    "                state_next = torch.Tensor([state_next])\n",
    "                reward = torch.tensor([reward]).unsqueeze(0)\n",
    "                \n",
    "                terminal = torch.tensor([int(terminal)]).unsqueeze(0)\n",
    "                \n",
    "                if(train):\n",
    "                    self.remember(state, action, reward, state_next, terminal)\n",
    "                    self.experience_replay()\n",
    "                \n",
    "                state = state_next\n",
    "                if terminal:\n",
    "                    #total_reward+=1\n",
    "                    if reward == 0:\n",
    "                        draw += 1\n",
    "                    elif reward > 0:\n",
    "                        win += 1\n",
    "                    else:\n",
    "                        loss += 1\n",
    "                    break\n",
    "            \n",
    "            total_rewards.append(total_reward)\n",
    "            \n",
    "            if ep_num != 0 and ep_num % 1000 == 0:\n",
    "                print(\"Episode {} score = {}, average score = {}\".format(ep_num + 1, total_rewards[-1], np.mean(total_rewards)))\n",
    "            #num_episodes += 1\n",
    "        if(not train):  \n",
    "            print(\"win: {} | draw: {} | loss: {}\".format(win/ num_episodes, draw / num_episodes, loss / num_episodes))\n",
    "        #print(\"Episode {} score = {}, average score = {}\".format(ep_num + 1, total_rewards[-1], np.mean(total_rewards)))\n",
    "        return total_rewards\n",
    "    \n",
    "    def train(self,num_episodes):\n",
    "        return self.run(num_episodes,True)\n",
    "    def test(self,num_episodes):\n",
    "        return self.run(num_episodes,False)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "env3 = BlackjackDoubleDownSplitEnv()\n",
    "env1 = BlackjackEnv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    " # can change the environmeent accordingly\n",
    "agent = DQNAgent(env3,\n",
    "                    max_memory_size=30000,\n",
    "                    batch_size=32,\n",
    "                    gamma=0.2,\n",
    "                    lr=0.0025,\n",
    "                    epsilon=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1001 score = 1.0, average score = -0.4695304695304695\n",
      "Episode 2001 score = -1.0, average score = -0.26686656671664166\n",
      "Episode 3001 score = -1.0, average score = -0.21059646784405198\n",
      "Episode 4001 score = -1.0, average score = -0.1802049487628093\n",
      "Episode 5001 score = -1.0, average score = -0.16556688662267546\n",
      "Episode 6001 score = 1.0, average score = -0.14730878186968838\n",
      "Episode 7001 score = 1.0, average score = -0.13226681902585344\n",
      "Episode 8001 score = -1.0, average score = -0.13248343957005373\n",
      "Episode 9001 score = 1.0, average score = -0.12698589045661593\n",
      "Episode 10001 score = 0.0, average score = -0.1136886311368863\n",
      "Episode 11001 score = 1.0, average score = -0.11017180256340332\n",
      "Episode 12001 score = 1.0, average score = -0.1044079660028331\n",
      "Episode 13001 score = 1.0, average score = -0.10160756864856549\n",
      "Episode 14001 score = -1.0, average score = -0.10206413827583743\n",
      "Episode 15001 score = 1.0, average score = -0.10139324045063662\n",
      "Episode 16001 score = 1.0, average score = -0.09668145740891194\n",
      "Episode 17001 score = -1.0, average score = -0.09558261278748309\n",
      "Episode 18001 score = -1.0, average score = -0.09277262374312538\n",
      "Episode 19001 score = 1.0, average score = -0.09036366507025946\n",
      "Episode 20001 score = 1.0, average score = -0.09049547522623869\n",
      "Episode 21001 score = 1.0, average score = -0.09028141517070616\n",
      "Episode 22001 score = 1.0, average score = -0.09095041134493886\n",
      "Episode 23001 score = 1.0, average score = -0.08956132342072083\n",
      "Episode 24001 score = -1.0, average score = -0.08982959043373193\n",
      "Episode 25001 score = 0.0, average score = -0.09007639694412224\n",
      "Episode 26001 score = -1.0, average score = -0.08880427675858621\n",
      "Episode 27001 score = 1.0, average score = -0.08825599051886968\n",
      "Episode 28001 score = -1.0, average score = -0.08581836362987036\n",
      "Episode 29001 score = -1.0, average score = -0.08585910830661012\n",
      "Episode 30001 score = -1.0, average score = -0.08686377120762641\n",
      "Episode 31001 score = 1.0, average score = -0.08638431018354246\n",
      "Episode 32001 score = -1.0, average score = -0.08602856160744976\n",
      "Episode 33001 score = -1.0, average score = -0.08536104966516166\n",
      "Episode 34001 score = 0.0, average score = -0.08602688156230699\n",
      "Episode 35001 score = 0.0, average score = -0.08439758864032457\n",
      "Episode 36001 score = 1.0, average score = -0.08241437737840615\n",
      "Episode 37001 score = 2.0, average score = -0.08253830977541148\n",
      "Episode 38001 score = -1.0, average score = -0.08562932554406463\n",
      "Episode 39001 score = 1.0, average score = -0.08345939847696213\n",
      "Episode 40001 score = -1.0, average score = -0.08322291942701432\n",
      "Episode 41001 score = 1.0, average score = -0.08441257530304139\n",
      "Episode 42001 score = 0.0, average score = -0.08421228065998429\n",
      "Episode 43001 score = -1.0, average score = -0.08481198111671821\n",
      "Episode 44001 score = 1.0, average score = -0.0852480625440331\n",
      "Episode 45001 score = -1.0, average score = -0.08508699806670963\n",
      "Episode 46001 score = 1.0, average score = -0.08569378926545075\n",
      "Episode 47001 score = -1.0, average score = -0.08516840067232612\n",
      "Episode 48001 score = -1.0, average score = -0.0846649028145247\n",
      "Episode 49001 score = -1.0, average score = -0.08446766392522602\n"
     ]
    }
   ],
   "source": [
    "rewards = agent.train(50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1001 score = -1.0, average score = -0.10989010989010989\n",
      "Episode 2001 score = 1.0, average score = -0.08395802098950525\n",
      "Episode 3001 score = 1.0, average score = -0.07964011996001333\n",
      "Episode 4001 score = 1.0, average score = -0.07398150462384404\n",
      "Episode 5001 score = 1.0, average score = -0.07978404319136173\n",
      "Episode 6001 score = 1.0, average score = -0.07782036327278787\n",
      "Episode 7001 score = 0.0, average score = -0.07813169547207542\n",
      "Episode 8001 score = -1.0, average score = -0.0811148606424197\n",
      "Episode 9001 score = -1.0, average score = -0.08654593934007332\n",
      "Episode 10001 score = -1.0, average score = -0.08709129087091291\n",
      "Episode 11001 score = -1.0, average score = -0.07926552131624398\n",
      "Episode 12001 score = -2.0, average score = -0.07649362553120573\n",
      "Episode 13001 score = -1.0, average score = -0.07722482885931851\n",
      "Episode 14001 score = 1.0, average score = -0.07842296978787229\n",
      "Episode 15001 score = 1.0, average score = -0.07799480034664355\n",
      "Episode 16001 score = 1.0, average score = -0.0748703206049622\n",
      "Episode 17001 score = -1.0, average score = -0.07028998294217988\n",
      "Episode 18001 score = 1.0, average score = -0.06960724404199767\n",
      "Episode 19001 score = -1.0, average score = -0.06794379243197726\n",
      "win: 0.42165 | draw: 0.09675 | loss: 0.4816\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 0.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 0.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 2.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 0.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 0.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 2.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 0.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 0.0,\n",
       " -2.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 0.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -2.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 0.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 0.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 2.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 0.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -2.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 0.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 0.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 0.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 2.0,\n",
       " 0.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 0.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 0.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -2.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -2.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 0.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 0.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 0.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -2.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -2.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 0.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 0.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 0.0,\n",
       " 2.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -2.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 0.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 0.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 0.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -2.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 0.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 0.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 2.0,\n",
       " -1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -2.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 0.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 0.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " -2.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " 1.0,\n",
       " -1.0,\n",
       " ...]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_rewards = agent.test(20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2b02dba3280>]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.arange(1,50001),rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f80d8b31525b6ea3adcf22249f5b1a58cdfe6d9f8b553721dcb1dc5ebfc8b9f9"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
